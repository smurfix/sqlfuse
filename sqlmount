#!/usr/bin/python -tt
# -*- coding: utf-8 -*-

#    Copyright (C) 2010  Matthias Urlichs <matthias@urlichs.de>
#
#    This program may be distributed under the terms of the GNU GPLv3.
#
## This file is formatted with tabs.
## Do NOT introduce leading spaces.

from __future__ import division, print_function, absolute_import

BLOCKSIZE = 4096

import errno, fcntl, os, stat, sys, traceback
from smurf import Db,Cf

import llfuse
from llfuse import FUSEError
import inspect
import traceback
from threading import Lock,Thread,Condition
from time import sleep

import datetime
def nowtuple():
	now = datetime.datetime.utcnow()
	return (int(now.strftime("%s")),int(now.strftime("%f000")))


def log_call():
	c=inspect.currentframe(1)
	print(">>>",c.f_code.co_name,"@",c.f_lineno,repr(c.f_locals))
	
def flag2mode(flags):
	if flags & os.O_APPEND:
		mode = "a"
	else:
		mode = "w"
	f = (flags & (os.O_WRONLY|os.O_RDONLY|os.O_RDWR))
	if f == os.O_RDONLY:
		mode = "r"
	elif f == os.O_RDWR:
		mode += "+"

	return mode

class BackgroundUpdater(Thread):
	def __init__(self,tree):
		super(BackgroundUpdater,self).__init__()
		self.tree = tree
		self.lock = Condition()
		self.state = False

	def run(self):
		while True:
			self.lock.acquire()
			while self.state is False:
				self.lock.wait()
			if self.state is None:
				self.lock.release()
				return
			self.state = False
			self.lock.release()

			with self.tree._update_lock:
				u = self.tree._update
				self.tree._update = {}
				self.tree._update_old = u
			for inode,data in u.iteritems():
				self.tree._inode_update1(inode,data)
			with self.tree._update_lock:
				self.tree._update_old = None
			self.tree.db.commit()

			sleep(0.5)
				

class FileOperations(object):
	mtime = None
	def __init__(self, tree, inode, flags):
		self.tree = tree
		self.inode = inode
		self.lock = Lock()
		mode = flag2mode(flags)
		self.mode = mode[0]
		self.file = open(tree._file_path(inode),mode)
		self.size = os.fstat(self.file.fileno()).st_size
		self.tree.set_busy(inode)

	def read(self, length,offset):
		with self.lock:
			self.tree._inode_set(self.inode,"atime",nowtuple(), do_time=False)
			self.file.seek(offset)
			return self.file.read(length)

	def write(self, buf,offset):
		with self.lock:
			self.file.seek(offset)
			self.file.write(buf)
			
			end = offset+len(buf)
			if self.size < end:
				self.size = end
				self.tree._inode_set(self.inode,"size",end)
				# implicitly sets mtime
			else:
				self.tree._inode_set(self.inode,"mtime",nowtuple())
			self.tree.trigger_bg()
			return len(buf)

	def release(self):
		self.tree._inode_update(self.inode)
		self.file.close()
		if self.tree.clr_busy(self.inode):
			self.tree._remove(self.inode)

	def _fflush(self):
		self.file.flush()

	def fsync(self, data_only):
		if data_only and hasattr(os, 'fdatasync'):
			os.fdatasync(self.file.fileno())
		else:
			os.fsync(self.file.fileno())
			self.tree._inode_update(self.inode)

	def flush(self):
		self._fflush()

	def fgetattr(self):
		log_call()
		raise FUSEError(errno.EOPNOTSUPP)
		return os.fstat(self.fd)

	def ftruncate(self, len):
		log_call()
		raise FUSEError(errno.EOPNOTSUPP)
		self.file.truncate(len)

	def lock(self, cmd, owner, **kw):
		log_call()
		raise FUSEError(errno.EOPNOTSUPP)
		# The code here is much rather just a demonstration of the locking
		# API than something which actually was seen to be useful.

		# Advisory file locking is pretty messy in Unix, and the Python
		# interface to this doesn't make it better.
		# We can't do fcntl(2)/F_GETLK from Python in a platfrom independent
		# way. The following implementation *might* work under Linux. 
		#
		# if cmd == fcntl.F_GETLK:
		#     import struct
		# 
		#     lockdata = struct.pack('hhQQi', kw['l_type'], os.SEEK_SET,
		#                            kw['l_start'], kw['l_len'], kw['l_pid'])
		#     ld2 = fcntl.fcntl(self.fd, fcntl.F_GETLK, lockdata)
		#     flockfields = ('l_type', 'l_whence', 'l_start', 'l_len', 'l_pid')
		#     uld2 = struct.unpack('hhQQi', ld2)
		#     res = {}
		#     for i in xrange(len(uld2)):
		#          res[flockfields[i]] = uld2[i]
		#  
		#     return fuse.Flock(**res)

		# Convert fcntl-ish lock parameters to Python's weird
		# lockf(3)/flock(2) medley locking API...
		op = { fcntl.F_UNLCK : fcntl.LOCK_UN,
			   fcntl.F_RDLCK : fcntl.LOCK_SH,
			   fcntl.F_WRLCK : fcntl.LOCK_EX }[kw['l_type']]
		if cmd == fcntl.F_GETLK:
			raise FUSEError(errno.EOPNOTSUPP)
		elif cmd == fcntl.F_SETLK:
			if op != fcntl.LOCK_UN:
				op |= fcntl.LOCK_NB
		elif cmd == fcntl.F_SETLKW:
			pass
		else:
			raise FUSEError(errno.EINVAL)

		fcntl.lockf(self.fd, op, kw['l_start'], kw['l_len'])

class DirOperations(object):
	mtime = None
	def __init__(self, tree, inode):
		self.inode = inode
		self.tree = tree

	def read(self, offset):
		# We use the actual inode as offset, except for . and ..
		# Fudge the value a bit so that there's no cycle.
		if offset <= 1:
			yield (".", self.tree.getattr(self.inode), 2)
			offset = 3
		if offset <= 4:
			if self.inode == self.tree.inode:
				par = self.inode
			else:
				par, = self.tree.db.DoFn("select parent from tree where inode=${inode}", inode=self.inode)
			yield ("..", self.tree.getattr(par), 5)
			offset = 6

		for n,i in self.tree.db.DoSelect("select name,inode from tree where parent=${par} and name != '' and inode > ${offset} order by inode", par=self.inode,offset=(offset-10)//2, _empty=True,_store=True):
			yield (n, self.tree.getattr(i), 2*i+11)

	def release(self):
		return

	def fsync(self):
		log_call()
		return


class SqlFuse(llfuse.Operations):
	node = Cf.get("SQL_NODE","default")
	user = Cf.get("SQL_USER",os.environ['USER'])
	password = Cf.get("SQL_PASS","")
	host=Cf.get("SQL_HOST","localhost")
	port=int(Cf.get("SQL_PORT",3306))
	database=Cf.get("SQL_DB","sqlfuse")
	dbtype=Cf.get("SQL_DBTYPE","mysql")

	def __init__(self,*a,**k):
		super(SqlFuse,self).__init__(*a,**k)
		self._slot = {}
		self._slot_next = 1
		self._busy = {}
		self._busy_lock = Lock()
		self._update = {}
		self._update_lock = Lock()
		self._update_old = None

# map fdnum â‡’ filehandle
	def new_slot(self,x):
		self._slot_next += 1
		while self._slot_next in self._slot:
			if self._slot_next == 999999999:
				self._slot_next = 1
			else:
				self._slot_next += 1
		self._slot[self._slot_next] = x
		return self._slot_next
	def old_slot(self,x):
		return self._slot[x]
	def del_slot(self,x):
		res = self._slot[x]
		del self._slot[x]
		return res

# busy-inode flag
	def set_busy(self,i):
		with self._busy_lock:
			if i in self._busy:
				if self._busy[i] > 0:
					self._busy[i] += 1
				else:
					self._busy[i] += 1
			else:
				self._busy[i] = 1
	def clr_busy(self,i):
		#return True if it's to be deleted
		with self._busy_lock:
			b = self._busy[i]
			if b < 0:
				b += 1
				if b == 0:
					del self._busy[i]
					return True
			else:
				b -= 1
				if b == 0:
					del self._busy[i]
			return False
	def defer_delete(self,i):
		with self._busy_lock:
			if i not in self._busy:
				return False
			if self._busy[i] > 0:
				self._busy[i] = -self._busy[i]
			return True
	def no_defer_delete(self,i):
		with self._busy_lock:
			if i not in self._busy:
				return
			if self._busy[i] < 0:
				self._busy[i] = -self._busy[i]

# background inode update
	def _inode_set(self, inode,attr,val, do_time=True):
		with self._update_lock:
			data = self._update.get(inode,None)
			if data is None:
				data = {}
				self._update[inode] = data
			data[attr] = val
			if not do_time:
				pass
			elif attr == "size":
				data["mtime"] = nowtuple()
			else:
				data["ctime"] = nowtuple()

	def _inode_get(self, inode,attr,val):
		with self._update_lock:
			u = self._update.get(inode,None)
			if not u and self._update_old:
				u = self._update_old.get(inode,None)
		if not u or attr not in u: return val
		return u[attr]
		
	def _inode_update(self, inode):
		with self._update_lock:
			data = self._update.get(inode,None)
			if not data: return
			if "_block" in data:
				data["_block"] += 1
				return
			del self._update[inode]
		self._inode_update1(inode,data)

	def _inode_delay(self, inode):
		self._inode_set(inode,"_block",0)
		self.db.call_committed(self._inode_nodelay, inode)

	def _inode_nodelay(self, inode):
		if self._update[inode].pop("_block"):
			self.trigger_bg()
		
	def _inode_update1(self, inode, data):
		a = []
		b = {}
		for f,v in data.items():
			a.append(f)
			if f.endswith("time"):
				b[f]=v[0]
				b[f+"ns"]=v[1]
			else:
				b[f]=v
		if "size" in data:
			with self._update_lock:
				sfilesize, = self.db.DoFn("select size from inode where id=${inode}", inode=inode)
				size = (data["size"]+BLOCKSIZE-1)//BLOCKSIZE
				nsz = data["size"]
				nsz = (nsz+BLOCKSIZE-1)//BLOCKSIZE
				if nsz != size:
					self.db.Do("update root set nblocks=nblocks+${szd} where id=${root}", root=self.root_id,szd=nsz-size, _empty=1)
				
		self.db.Do("update inode set "+(", ".join(("%s=${%s}"%(x,x) for x in a)))+" where id=${inode}", inode=inode,**b)
		

	def _file_path(self, inode):
		fp = []
		CHARS="ABCDEFGHIJKLMNOPQRSTUVWXYZ"
		ino = inode % 100
		inode //= 100
		while inode:
			fp.insert(0,CHARS[inode % len(CHARS)])
			inode //= len(CHARS)
		p = os.path.join(self.store, *fp)
		if not os.path.exists(p):
			os.makedirs(p, 0o700)
		if ino < 10:
			ino = "0"+str(ino)
		else:
			ino = str(ino)
		return os.path.join(p, ino)

#	def _inode_path(self, path, tail=0):
#		if path[0] != '/':
#			raise FUSEError(errno.ENOENT)
#		path = path.split('/')
#		while path:
#			name = path.pop()
#			if name != '':
#				break
#		if not tail:
#			path.append(name)
#		depth=0
#		q=[""]
#		qa = {"root":self.inode}
#		for p in path:
#			if p == '':
#				continue
#			depth += 1
#			q.append("JOIN tree AS t%d ON t%d.inode = t%d.parent and t%d.name=${t%d_name}" % (depth, depth-1, depth, depth, depth))
#			qa["t"+str(depth)+"_name"] = p
#		q[0]="SELECT t%d.inode from tree as t0" % (depth,)
#		q.append("where t0.inode=${root}")
#		ino, = self.db.DoFn(" ".join(q),**qa)
#		return ino,name

	def _lookup(self, inode_p, name):
		if name == '.':
			inode = inode_p
		elif name == '..':
			inode, = self.db.DoFn("select parent from tree where inode=${inode}",inode=inode_p)
		else:
			try:
				inode, = self.db.DoFn("select inode from tree where parent=${inode} and name=${name}", inode=inode_p, name=name)
			except Db.NoData:
				raise(llfuse.FUSEError(errno.ENOENT))
		return inode
	    
	def lookup(self, inode_p, name):
		return self.getattr(self._lookup(inode_p,name))

	def handle_exc(self,fn,exc):
		traceback.print_exc()
		self.db.rollback()

	def done(self, exc = None):
		if exc is None:
			self.db.commit()
		else:
			self.db.rollback()

	def getattr(self, inode):
		res = llfuse.EntryAttributes()
		res.st_ino = inode
		res.st_nlink, = self.db.DoFn("select count(*) from tree where inode=${inode}",inode=inode)
		d = self.db.DoFn("select * from inode where id=${inode}", inode=inode, _dict=1)
		for k in ("size mode uid gid atime mtime ctime rdev".split()):
			if k.endswith("time"):
				try:
					v = self._inode_get(inode,k,None)
					if v is None:
						v = (d[k],d[k+"_ns"])
					setattr(res,"st_"+k, v[0])
					setattr(res,"st_"+k+"_ns", v[1])
				except TypeError:
					raise TypeError("float %s got %r (%s)"%(k,d[k],d[k].__class__.__name__))
			else:
				setattr(res,"st_"+k, self._inode_get(inode,k,d[k]))
		if stat.S_ISDIR(res.st_mode): 
			res.st_nlink += 2
		res.st_blocks = (d['size']+BLOCKSIZE-1)//BLOCKSIZE
		res.st_blksize = BLOCKSIZE
		res.st_dev=0
		res.st_rdev=0
		res.generation = 1 ## TODO: store in DB
		res.attr_timeout = 10
		res.entry_timeout = 10
		return res

	def setattr(self, inode, attr):
		if attr.st_size is not None:
			with file(self._file_path(inode),"r+") as f:
				f.truncate(attr.st_size)
		for f in ("size uid gid atime mtime rdev".split()):
			v = getattr(attr,"st_"+f)
			if v is not None:
				self._inode_set(inode,f,v)
		return self.getattr(inode)

	def readlink(self, inode):
		log_call()
		raise FUSEError(errno.EOPNOTSUPP)

	def opendir(self, inode):
		return self.new_slot(DirOperations(tree=self, inode=inode))

	def readdir(self, fh, offset):
		return self.old_slot(fh).read(offset)
		
	def fsyncdir(self, fh):
		log_call()
		return self.old_slot(fh).fsync()

	def releasedir(self, fh):
		return self.del_slot(fh).release()

	def unlink(self, inode_p, name):
		inode = self._lookup(inode_p,name)
		mode, = self.db.DoFn("select mode from inode where id=${inode}", inode=inode)
		if stat.S_ISDIR(mode):
			raise FUSEError(errno.EISDIR)
		if not self.defer_delete(inode):
			self._remove(inode)

	def rmdir(self, inode_p, name):
		inode = self._lookup(inode_p,name)
		mode, = self.db.DoFn("select mode from inode where id=${inode}", inode=inode)
		if not stat.S_ISDIR(mode):
			raise FUSEError(errno.ENOTDIR)
		cnt, = self.db.DoFn("select count(*) from tree where parent=${inode}", inode=inode)
		if cnt:
			raise FUSEError(errno.ENOTEMPTY)
		self._remove(inode)

	def _remove(self,inode):
		try:
			os.unlink(self._file_path(inode))
		except OSError as e:
			if e.errno != errno.ENOENT:
				raise
		mode,size = self.db.DoFn("select mode,size from inode where id=${inode}", inode=inode)
		self.db.Do("delete from tree where inode=${inode}", inode=inode)
		self.db.Do("delete from inode where id=${inode}", inode=inode)
		size = (size+BLOCKSIZE-1)//BLOCKSIZE
		self.db.Do("update root set nfiles=nfiles-1 where id=${root} and nfiles>0", root=self.root_id, _empty=1)
		self.db.Do("update root set nblocks=nblocks-${size} where id=${root} and nblocks>0", root=self.root_id,size=size, _empty=1)

	def symlink(self, path, path1):
		log_call()
		raise FUSEError(errno.EOPNOTSUPP)

	def rename(self, path, path1):
		log_call()
		raise FUSEError(errno.EOPNOTSUPP)

	def link(self, path, path1):
		log_call()
		raise FUSEError(errno.EOPNOTSUPP)

	def chmod(self, path, mode):
		log_call()
		raise FUSEError(errno.EOPNOTSUPP)

	def chown(self, path, user, group):
		log_call()
		raise FUSEError(errno.EOPNOTSUPP)

	def truncate(self, path, len):
		log_call()
		raise FUSEError(errno.EOPNOTSUPP)
		#f = open("." + path, "a")
		#f.truncate(len)
		#f.close()

	def mknod(self, parent, name, mode, rdev, ctx):
		log_call()
		ino = self._new_inode(parent,name,mode,ctx,rdev)
		return self.getattr(ino)

	def mkdir(self, parent, name, mode, ctx):
		ino = self._new_inode(parent,name,(mode&0o7777)|stat.S_IFDIR,ctx)
		return self.getattr(ino)

	def utime(self, path, times):
		log_call()
		raise FUSEError(errno.EOPNOTSUPP)

#    The following utimens method would do the same as the above utime method.
#    We can't make it better though as the Python stdlib doesn't know of
#    subsecond preciseness in acces/modify times.
#  
	def utimens(self, path, ts_acc, ts_mod):
		log_call()
		raise FUSEError(errno.EOPNOTSUPP)

	def bmap(self, *a,**k):
		log_call()
		raise FUSEError(errno.EOPNOTSUPP)

## not called because default_permissions is set
#	def access(self, inode, mode, ctx):
#		log_call()
#		raise FUSEError(errno.EOPNOTSUPP)

#    This is how we could add stub extended attribute handlers...
#    (We can't have ones which aptly delegate requests to the underlying fs
#    because Python lacks a standard xattr interface.)
#
	def getxattr(self, inode, name):
		raise FUSEError(errno.EOPNOTSUPP)
		val = name.swapcase() + '@' + path
		if size == 0:
			# We are asked for size of the value.
			return len(val)
		return val

	def setxattr(self, inode, name, value):
		raise FUSEError(errno.EOPNOTSUPP)
		# TODO
		return

	def listxattr(self, inode):
		raise FUSEError(errno.EOPNOTSUPP)
		# We use the "user" namespace to please XFS utils
		aa = ["user." + a for a in ("foo", "bar")]
		if size == 0:
			# We are asked for size of the attr list, ie. joint size of attrs
			# plus null separators.
			return len("".join(aa)) + len(aa)
		return aa

	def removexattr(self, inode, name):
		raise FUSEError(errno.EOPNOTSUPP)
		# TODO
		return

	def statfs(self):
		"""
		Should return an object with statvfs attributes (f_bsize, f_frsize...).
		Eg., the return value of os.statvfs() is such a thing (since py 2.2).
		If you are not reusing an existing statvfs object, start with
		fuse.StatVFS(), and define the attributes.

		To provide usable information (ie., you want sensible df(1)
		output, you are suggested to specify the following attributes:

			- f_bsize - preferred size of file blocks, in bytes
			- f_frsize - fundamental size of file blcoks, in bytes
				[if you have no idea, use the same as blocksize]
			- f_blocks - total number of blocks in the filesystem
			- f_bfree - number of free blocks
			- f_files - total number of file inodes
			- f_ffree - nunber of free file inodes
		"""
		s = llfuse.StatvfsData()
		osb = os.statvfs(self.store)
		s.f_bsize = BLOCKSIZE
		s.f_frsize = BLOCKSIZE
		s.f_blocks,s.f_files = self.db.DoFn("select nblocks,nfiles from root where id=${root}", root=self.root_id)
		s.f_bfree = (osb.f_bfree * osb.f_bsize) // BLOCKSIZE
		s.f_bavail = (osb.f_bavail * osb.f_bsize) // BLOCKSIZE
		s.f_ffree = osb.f_ffree
		s.f_favail = osb.f_favail
		s.f_namemax = 1023

		s.f_blocks += s.f_bfree
		s.f_files += s.f_ffree
		return s

	def open(self, inode,flags):
		res = FileOperations(tree=self, inode=inode, flags=flags)
		return self.new_slot(res)

	def _new_inode(self, par,name,mode,ctx,rdev=None):
		now,now_ns = nowtuple()
		ino = self.db.Do("insert into inode (mode,uid,gid,atime,mtime,ctime,atime_ns,mtime_ns,ctime_ns,rdev) values(${mode},${uid},${gid},${now},${now},${now},${now_ns},${now_ns},${now_ns},${rdev})", mode=mode, uid=ctx.uid,gid=ctx.gid, now=now,now_ns=now_ns,rdev=rdev)
		self.db.Do("insert into tree (inode,parent,name) values(${ino},${par},${name})", ino=ino,par=par,name=name)
		
		self.db.Do("update root set nfiles=nfiles+1 where id=${root}", root=self.root_id, _empty=1)
		self._inode_delay(ino)
		return ino

	def create(self, par,name,mode,ctx):
		ino = None
		try:
			ino, = self.db.DoFn("select inode from tree where parent=${par} and name=${name}", par=par,name=name)
		except Db.NoData:
			ino = self._new_inode(par,name,mode|stat.S_IFREG,ctx)
		else:
			if flags & os.O_EXCL:
				raise FUSEError(errno.EEXIST)

		res = FileOperations(tree=self, inode=ino, flags=os.O_RDWR|os.O_CREAT)
		return (self.new_slot(res),self.getattr(ino))

	def read(self, fh,off,size):
		return self.old_slot(fh).read(size,off)

	def write(self, fh,off,buf):
		return self.old_slot(fh).write(buf,off)

	def release(self, fh):
		return self.del_slot(fh).release()

	def _fflush(self):
		log_call()
		raise FUSEError(errno.EOPNOTSUPP)
		if 'w' in self.file.mode or 'a' in self.file.mode:
			self.file.flush()

	def fsync(self, fh,data_only): #isfsyncfile):
		return self.old_slot(fh).fsync(data_only)

	def flush(self, fh):
		self.old_slot(fh).flush()

	def fgetattr(self, *a,**k):
		log_call()
		raise FUSEError(errno.EOPNOTSUPP)
		return os.fstat(self.fd)

	def ftruncate(self, *a,**k):
		log_call()
		raise FUSEError(errno.EOPNOTSUPP)
		self.file.truncate(len)

	def lock(self, *a,**k): #cmd, owner):
		log_call()
		raise FUSEError(errno.EOPNOTSUPP)
		# The code here is much rather just a demonstration of the locking
		# API than something which actually was seen to be useful.

		# Advisory file locking is pretty messy in Unix, and the Python
		# interface to this doesn't make it better.
		# We can't do fcntl(2)/F_GETLK from Python in a platfrom independent
		# way. The following implementation *might* work under Linux. 
		#
		# if cmd == fcntl.F_GETLK:
		#     import struct
		# 
		#     lockdata = struct.pack('hhQQi', kw['l_type'], os.SEEK_SET,
		#                            kw['l_start'], kw['l_len'], kw['l_pid'])
		#     ld2 = fcntl.fcntl(self.fd, fcntl.F_GETLK, lockdata)
		#     flockfields = ('l_type', 'l_whence', 'l_start', 'l_len', 'l_pid')
		#     uld2 = struct.unpack('hhQQi', ld2)
		#     res = {}
		#     for i in xrange(len(uld2)):
		#          res[flockfields[i]] = uld2[i]
		#  
		#     return fuse.Flock(**res)

		# Convert fcntl-ish lock parameters to Python's weird
		# lockf(3)/flock(2) medley locking API...
		op = { fcntl.F_UNLCK : fcntl.LOCK_UN,
			   fcntl.F_RDLCK : fcntl.LOCK_SH,
			   fcntl.F_WRLCK : fcntl.LOCK_EX }[kw['l_type']]
		if cmd == fcntl.F_GETLK:
			raise FUSEError(errno.EOPNOTSUPP)
		elif cmd == fcntl.F_SETLK:
			if op != fcntl.LOCK_UN:
				op |= fcntl.LOCK_NB
		elif cmd == fcntl.F_SETLKW:
			pass
		else:
			raise FUSEError(errno.EINVAL)

		fcntl.lockf(self.fd, op, kw['l_start'], kw['l_len'])

	def init_db(self,db,node):
		# TODO: setup a copying thread
		self.db = db
		try:
			self.node_id,self.root_id,self.inode,self.store = self.db.DoFn("select node.id,root.id,root.inode,node.files from node,root where root.id=node.root and node.name=${name}", name=self.node)
		except Db.NoData:
			raise RuntimeError("data for '%s' is missing"%(self.node,))
		try:
			mode,=db.DoFn("select mode from inode where id=${inode}",inode=self.inode)
		except Db.NoData:
			raise RuntimeError("database has not been initialized: inode %d is missing" % (self.inode,))
		if mode == 0:
			db.Do("update inode set mode=${dir} where id=${inode}", dir=stat.S_IFDIR|stat.S_IRWXU|stat.S_IRWXG|stat.S_IRWXO, inode=self.inode)

	def trigger_bg(self, s=True):
		self.dbt.lock.acquire()
		if self.dbt.state is False or s is None:
			self.dbt.state = s
			self.dbt.lock.notify()
		self.dbt.lock.release()

	def init(self):
		self.dbt = BackgroundUpdater(self)
		self.dbt.start()

	def destroy(self):
		self.trigger_bg(None) # shutdown updater thread
		self.dbt.join()
		pass

def opts(server,p=None,usage=None):
	from fuseparts.subbedopts import SubbedOptParse
	if p is False:
		def opt(name,**k):
			p.add_option('-o', subopt=name, **k)
		def rv():
			return p.print_help()
		p = SubbedOptParse(usage=usage)
	elif p is None:
		def opt(name,**k):
			p.add_option('-o', subopt=name, **k)
		def rv():
			return p.parse_args(sys.argv[2:])
		p = SubbedOptParse(usage=usage)
	else:
		from optparse import OptionParser
		p = OptionParser(usage=usage)
		def opt(name,**k):
			p.add_option('--'+name, **k)
		def rv():
			return p.parse_args(sys.argv[1:])

	opt("node", dest="node", default="node",
		help="file storage node name [default: %default]")
	opt("user", dest="username", default=server.user,
		help="SQL user name [default: %default]")
	opt("password", dest="password", default=server.password,
		help="SQL password [default: %default]")
	opt("host", dest="host", default=server.host,
		help="SQL database host [default: %default]")
	opt("port", dest="port", default=server.port, type="int",
		help="SQL database name [default: %default]")
	opt("database", dest="database", default=server.database,
		help="SQL database name [default: %default]")
	opt("dbtype", dest="dbtype", default=server.dbtype,
		help="SQL database type [default: %default]")

	return rv()

def main():
	if len(sys.argv) < 2 or sys.argv[1] == "help":
		usage = """
sqlmount /mountpoint [options ...]
	Mount an SQL-based file system.
sqlmount --help
	Print usage information for mounting.

sqlmount help
	Print usage information for non-mounting modes.

*sqlmount info [--node=NAME] [path...]
	List generic information for this SQL node.
	If paths are specified, list the detailed state for that file/dir.

*sqlmount list nodes
	List which nodes are known.
*sqlmount list node NAME
	List details from the named node.
*sqlmount add node NAME path STORAGE
	Create a new directory hierarchy for storing in STORAGE.
*sqlmount change node NAME [new NAME] [path STORAGE]
	Change this directory hierarchy for storing in STORAGE.
	You need to copy files from the old to the new storage
	before running this command!
*sqlmount clone node NAME new NAME path STORAGE
	Create a copy of an existing directory hierarchy.
	You'll also need to specify where to copy files from; see below.
*sqlmount del node NAME
	Delete this node.

*sqlmount list copy
	List all copying commands.
*sqlmount list copy A B
	List details of the copy command which copies stuff from node A to B.
*sqlmount add copy A B prio N mode HOW via CMD [ondemand|background]
*sqlmount change copy A B [prio N] [mode HOW [via CMD]] [ondemand|background]
	Add or change a command to copy stuff from A to B.
	If 'ondemand' is specified, this is a caching method.
	Otherwise, copying of all files will run in the background.
*sqlmount del copy A B
	Delete this method to copy files.

* These commands are not implemented yet.
"""
		p=opts(SqlFuse,False,usage)
		sys.exit(0)
	else:
		usage = """
sqlmount /path -o option...: mount a file hierarchy from a SQL database.

sqlmount help  -- list other modes and options
""" 

		server = SqlFuse()
		opt,arg = opts(server, usage=usage)

		db = Db.Db(dbtye=opt.dbtype,host=opt.host,port=opt.port,database=opt.database,username=opt.username,password=opt.password)
		server.init_db(db, opt.node)
	
		llfuse.init(server, sys.argv[1], 
			[  b'fsname=SqlFuse', b'nonempty', b'max_read=1048576', b'default_permissions', b'allow_other', b'dev', b'suid'])
		try:
			llfuse.main()
		finally:
			llfuse.close()
		

if __name__ == '__main__':
	main()
